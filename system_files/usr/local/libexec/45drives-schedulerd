#!/usr/bin/env python3
import os, json, pwd, subprocess, pathlib, logging, grp, signal
import dbus, dbus.service, dbus.mainloop.glib
import gi
gi.require_version('Polkit', '1.0')
from gi.repository import GLib, Polkit
from typing import List

# ---- IDs
BUS_NAME  = 'org.houston.Scheduler'
OBJ_PATH  = '/org/houston/Scheduler'
IFACE     = 'org.houston.Scheduler1'

# ---- Layout
SCRIPTS_DIR    = pathlib.Path('/opt/45drives/houston/scheduler/scripts')
TEMPLATES_DIR  = pathlib.Path('/opt/45drives/houston/scheduler/templates')
STATE_ROOT     = pathlib.Path('/var/lib/45drives/houston/scheduler')     # per-user state (.env/.json/.txt, registry) + unit files

# Optional marker support (legacy)
MARKER_NAME    = '.houston'

ROOT_TEMPLATES = {'AutomatedSnapshotTask','ZfsReplicationTask','ScrubTask','SmartTest'}
USER_TEMPLATES = {'RsyncTask','CloudSyncTask'}

logging.basicConfig(level=logging.INFO, format='[schedulerd] %(levelname)s: %(message)s')

def ensure(p: pathlib.Path, mode=0o755):
    p.mkdir(parents=True, exist_ok=True)
    try: os.chmod(p, mode)
    except Exception: pass
    

# ---- Small helpers to make subprocesses quick & interruptible
def _run_quiet(argv, *, timeout=8, check=False):
    try:
        return subprocess.run(
            argv,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True,
            timeout=timeout,
            check=check
        )
    except subprocess.TimeoutExpired as e:
        logging.error("Command timed out: %s", ' '.join(argv))
        raise
    except subprocess.CalledProcessError as e:
        # Let callers decide; we still log the useful bits.
        logging.error("Command failed [%s]: %s\nSTDOUT:\n%s\nSTDERR:\n%s",
                      e.returncode, ' '.join(argv), e.stdout, e.stderr)
        if check:
            raise
        return e  # return object with .returncode

def _cmd_out(argv, *, timeout=6):
    try:
        cp = _run_quiet(argv, timeout=timeout)
        return cp.stdout if cp.returncode == 0 else ''
    except (FileNotFoundError, subprocess.TimeoutExpired):
        return ''

class Daemon(dbus.service.Object):
    def __init__(self, bus, loop, name_owner):
        super().__init__(bus, OBJ_PATH)
        self.bus = bus
        self.loop = loop
        self.name_owner = name_owner

    # ---- Caller identity + polkit
    def _ids_from_sender(self, sender):
        dbus_obj = self.bus.get_object('org.freedesktop.DBus', '/org/freedesktop/DBus')
        api = dbus.Interface(dbus_obj, 'org.freedesktop.DBus')
        pid = int(api.GetConnectionUnixProcessID(sender))
        uid = int(api.GetConnectionUnixUser(sender))
        return pid, uid

    def _username_from_sender(self, sender):
        pid, uid = self._ids_from_sender(sender)

        # Prefer the loginuid of the caller process (cockpit-bridge keeps the real user here)
        try:
            with open(f"/proc/{pid}/loginuid", "r") as f:
                luid = int((f.read() or "").strip())
            if luid >= 0:
                return pwd.getpwuid(luid).pw_name
        except Exception:
            pass

        # Fallback to the D-Bus connection uid
        return pwd.getpwuid(uid).pw_name

    def _auth(self, action_id, sender):
        pid, _ = self._ids_from_sender(sender)
        auth = Polkit.Authority.get_sync(None)
        res = auth.check_authorization_sync(
            Polkit.UnixProcess.new(pid),
            action_id, None,
            Polkit.CheckAuthorizationFlags.ALLOW_USER_INTERACTION,
            None
        )
        if not (res.get_is_authorized() or res.get_is_challenge()):
            raise PermissionError(f'Not authorized for {action_id}')

    # ---- Helpers (naming)
    def _unit_base(self, template: str, name: str) -> str:
        return f'houston_scheduler_{template}_{name}'

    def _unit_user(self, template: str, name: str, user: str) -> str:
        uid, _, _ = self._user_ids(user)
        return f'houston_scheduler_{template}_{name}_u{uid}'
    
    # NEW: task dir is keyed by task *name*
    def _task_dir(self, user: str, task_name: str) -> pathlib.Path:
        p = STATE_ROOT / user / task_name
        ensure(p)
        return p

    # Legacy state (old layout was keyed by <unit>)
    def _legacy_state_dir(self, user: str, unit: str) -> pathlib.Path:
        p = STATE_ROOT / user / unit
        return p

    # Pick new dir if present, else legacy
    def _find_task_dir(self, user: str, task_name: str, unit: str) -> pathlib.Path:
        nd = STATE_ROOT / user / task_name
        if nd.exists():
            return nd
        ld = self._legacy_state_dir(user, unit)
        return nd if nd.exists() else ld

    def _find_user_owner_any(self, template: str, name: str) -> str:
        """
        Search STATE_ROOT/<user>/<name>/<unit_user>.service to find the owning user
        for a user-scope task. Returns username or '' if not found.
        """
        if not STATE_ROOT.exists():
            return ''
        for entry in STATE_ROOT.iterdir():
            if not entry.is_dir():
                continue
            user = entry.name
            try:
                unit = self._unit_user(template, name, user)
            except KeyError:
                continue
            cand = entry / name / f'{unit}.service'
            if cand.exists():
                return user
        return ''
    
    def _owner_for(self, template: str, name: str, sender) -> str:
        # Prefer the real owner on disk; fall back to the DBus senderâ€™s user
        return self._find_user_owner_any(template, name) or self._username_from_sender(sender)

    def _write_user_task_files(self, user: str, template: str, name: str,
                            env: dict, schedule: dict, notes: str, script_path: str):
        """Write env/json/txt + .service/.timer for a user task (idempotent)."""
        unit = self._unit_user(template, name, user)
        task_dir = self._task_dir(user, name)

        env_text = '\n'.join([f'{k}={v}' for k, v in env.items() if str(v) not in ('', '0')])
        (task_dir / f'{unit}.env').write_text(env_text)
        (task_dir / f'{unit}.json').write_text(json.dumps(schedule, indent=2))
        (task_dir / f'{unit}.txt').write_text(notes or '')

        svc_tpl = (TEMPLATES_DIR / 'Task.service').read_text()
        exec_start = f'/usr/bin/python3 {script_path}'
        svc_text = (svc_tpl
                    .replace('{task_name}', unit)
                    .replace('{env_path}', str(task_dir / f'{unit}.env'))
                    .replace('{ExecStart}', exec_start))
        (task_dir / f'{unit}.service').write_text(svc_text)

        tim_tpl = (TEMPLATES_DIR / 'Schedule.timer').read_text()
        oncal_lines = self._oncalendar_lines(schedule)
        tim_text = (tim_tpl
                    .replace('{description}', f'Timer for {unit}')
                    .replace('{unit_name}', unit)
                    .replace('{on_calendar_lines}', oncal_lines))
        (task_dir / f'{unit}.timer').write_text(tim_text)

        self._link_user_units(user, task_dir, unit)
        if schedule.get('enabled'):
            self._systemctl_user(user, f'systemctl --user start {unit}.timer')
        else:
            # Best-effort to stop if previously enabled
            try: self._systemctl_user(user, f'systemctl --user stop {unit}.timer || true')
            except Exception: pass

    # ---- Paths
    def _registry_path(self, user):
        ensure(STATE_ROOT / user)
        p = STATE_ROOT / user / 'tasks.json'
        if not p.exists():
            p.write_text('[]\n')
        return p

    def _user_ids(self, user):
        e = pwd.getpwnam(user)
        return e.pw_uid, e.pw_gid, e.pw_dir

    def _runtime_user_unit_dir(self, user):
        uid, _, _ = self._user_ids(user)
        return pathlib.Path(f'/run/user/{uid}/systemd/user')

    def _systemctl_user(self, user, cmd):
        """Run a systemctl --user command for 'user', ensuring the user manager is addressable."""
        uid, _, _ = self._user_ids(user)

        # ensure a user manager exists (non-fatal if these fail/timeout)
        try: _run_quiet(['loginctl', 'enable-linger', user], timeout=4)
        except Exception: pass
        try: _run_quiet(['systemctl', 'start', f'user@{uid}.service'], timeout=4)
        except Exception: pass

        # export both vars so systemctl can talk to the user bus
        env1 = f'XDG_RUNTIME_DIR=/run/user/{uid}'
        env2 = f'DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/{uid}/bus'

        full = ['runuser', '-u', user, '--', 'env', env1, env2, 'bash', '-lc', cmd]
        cp = _run_quiet(full, timeout=12)  # keep tight so restarts aren't held up

        if cp.returncode != 0:
            logging.error(
                "systemctl --user failed (user=%s): %s\nSTDOUT:\n%s\nSTDERR:\n%s",
                user, cmd, cp.stdout, cp.stderr
            )
            raise RuntimeError(
                f"systemctl --user failed (user={user}): {cmd}\n"
                f"rc={cp.returncode}\nSTDOUT:\n{cp.stdout}\nSTDERR:\n{cp.stderr}"
            )

    def _fragment(self, user, unit):  # 'unit' = 'x.service' or 'x.timer'
        out = self._systemctl_user_out(user, f'systemctl --user show {unit} --no-pager --property=FragmentPath')
        return (out.split('=',1)[1].strip() if 'FragmentPath=' in out else '')

    def _unlink_runtime_slot(self, user, unit):
        try:
            uid,_,_ = self._user_ids(user)
            rp = pathlib.Path(f'/run/user/{uid}/systemd/user/{unit}')
            rp.unlink()
        except FileNotFoundError:
            pass
        except Exception:
            pass

    def _safe_link_one(self, user, unit_dir: pathlib.Path, unit: str, kind: str):
        """kind = 'service' or 'timer'"""
        want = str(unit_dir / f'{unit}.{kind}')
        have = self._fragment(user, f'{unit}.{kind}')

        # if already linked to the right file, done
        if have and os.path.abspath(have) == want:
            return

        # if linked to something else, unlink that exact path (legacy, etc.)
        if have:
            try:
                self._systemctl_user(user, f'systemctl --user unlink "{have}" || true')
            except Exception:
                pass

        # also nuke the runtime slot to avoid "already exists" errors
        self._unlink_runtime_slot(user, f'{unit}.{kind}')

        # now link to our new file
        self._systemctl_user(user, f'systemctl --user link --runtime "{want}"')

    def _link_user_units(self, user, unit_dir: pathlib.Path, unit: str):
        try: self._systemctl_user(user, 'systemctl --user daemon-reload || true')
        except Exception: pass

        # stop/disable if needed; ignore errors
        try: self._systemctl_user(user, f'systemctl --user stop {unit}.timer || true')
        except Exception: pass
        try: self._systemctl_user(user, f'systemctl --user stop {unit}.service || true')
        except Exception: pass

        # link (idempotent)
        self._safe_link_one(user, unit_dir, unit, 'service')
        try: self._safe_link_one(user, unit_dir, unit, 'timer')
        except Exception:
            pass

        try: self._systemctl_user(user, 'systemctl --user daemon-reload || true')
        except Exception: pass


    # ---------- ZFS roots discovery (NO config file) ----------
    def _zfs_pool_mounts(self):
        """
        Return mountpoints of top-level ZFS pools.
        1) Prefer `zpool list` + `zfs get mountpoint <pool>`
        2) Fallback: parse /proc/self/mounts (fstype=zfs), keep shallowest mountpoints.
        """
        mps = set()

        pools_txt = _cmd_out(['zpool', 'list', '-H', '-o', 'name']).strip()
        if pools_txt:
            for pool in pools_txt.splitlines():
                pool = pool.strip()
                if not pool:
                    continue
                mp = _cmd_out(['zfs', 'get', '-H', '-o', 'value', 'mountpoint', pool]).strip()
                if mp and mp != '-' and os.path.isdir(mp):
                    mps.add(pathlib.Path(mp))

        if not mps:
            try:
                with open('/proc/self/mounts', 'r') as f:
                    lines = f.read().splitlines()
                zfs_mps = [pathlib.Path(l.split()[1]) for l in lines if len(l.split()) >= 3 and l.split()[2] == 'zfs']
                zfs_mps = [p for p in zfs_mps if p.exists()]
                zset = set(zfs_mps)
                for p in zfs_mps:
                    if p.parent not in zset:
                        mps.add(p)
            except Exception as e:
                logging.debug("mounts parse failed: %s", e)

        return sorted(mps, key=lambda p: (len(p.parts), str(p)))

    def _backup_roots(self):
        """
        Return subdirectories under each ZFS pool mountpoint whose group owner is 'smbusers'.
        These are treated as "backup roots".
        """
        try:
            gid = grp.getgrnam('smbusers').gr_gid
        except KeyError:
            logging.warning("Group 'smbusers' not found; no backup roots will be discovered.")
            return []

        roots = []
        for pool_mp in self._zfs_pool_mounts():
            try:
                for entry in pool_mp.iterdir():
                    if not entry.is_dir():
                        continue
                    try:
                        st = entry.stat()
                    except FileNotFoundError:
                        continue
                    if st.st_gid == gid:
                        roots.append(entry.resolve())
            except Exception as e:
                logging.debug("scan error in %s: %s", pool_mp, e)

        # de-dupe
        seen = set(); out=[]
        for r in roots:
            if r not in seen:
                seen.add(r); out.append(r)
        return out

    def _list_user_owned_dirs(self, base: pathlib.Path, uid: int):
        """
        Immediate subdirs of `base` that are owned by `uid`.
        Also accept a subdir that contains a legacy marker directory (MARKER_NAME).
        """
        out = []
        try:
            for entry in base.iterdir():
                if not entry.is_dir():
                    continue
                try:
                    st = entry.stat()
                except FileNotFoundError:
                    continue
                if st.st_uid == uid or (entry / MARKER_NAME).is_dir():
                    out.append(str(entry))
        except Exception as e:
            logging.debug("scan error in %s: %s", base, e)
        return sorted(out)
    
    def _systemctl_user_out(self, user, cmd):
        """Run systemctl --user CMD and return stdout; ensure user manager exists."""
        uid, _, _ = self._user_ids(user)
        # ensure a user manager exists (best effort)
        try: _run_quiet(['loginctl', 'enable-linger', user], timeout=4)
        except Exception: pass
        try: _run_quiet(['systemctl', 'start', f'user@{uid}.service'], timeout=4)
        except Exception: pass

        env1 = f'XDG_RUNTIME_DIR=/run/user/{uid}'
        env2 = f'DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/{uid}/bus'
        full = ['runuser','-u',user,'--','env',env1,env2,'bash','-lc', cmd]
        cp = _run_quiet(full, timeout=12)  # no check=True; we want stdout even on non-zero
        return cp.stdout if hasattr(cp,'stdout') else ''

    def _discover_user_units(self, user: str):
        """
        Yield tuples (template, name, unit, task_dir) for any unit files
        under STATE_ROOT/<user>/* that look like houston_scheduler_*.
        """
        out = []
        base = STATE_ROOT / user
        if not base.exists():
            return out
        for entry in base.iterdir():
            if not entry.is_dir():
                continue
            # Look for *.service with canonical basename
            for svc in entry.glob('*.service'):
                bn = svc.stem  # unit without .service
                if not bn.startswith('houston_scheduler_'):
                    continue
                # Strip optional _u<uid> suffix first, from the RIGHT
                core = bn
                idx = core.rfind('_u')
                if idx != -1 and core[idx+2:].isdigit():
                    core_no_uid = core[:idx]
                else:
                    core_no_uid = core
                # remove prefix and split once: houston_scheduler_<Template>_<TaskName>
                rest = core_no_uid[len('houston_scheduler_'):]
                if '_' not in rest:
                    continue
                template, name = rest.split('_', 1)
                out.append((template, name, bn, entry))
        return out

        
    # ---- OnCalendar builder ------------------------------------------------------
    DOW_NAMES = ['Sun','Mon','Tue','Wed','Thu','Fri','Sat']
    DOW_IDX   = {n.lower(): i for i, n in enumerate(DOW_NAMES)}

    @staticmethod
    def _pad2(x: str) -> str:
        try:
            return f"{int(str(x), 10):02d}"
        except Exception:
            return str(x)

    @classmethod
    def _dow_expr(cls, interval: dict) -> str:
        raw = interval.get('dayOfWeek') or []
        out: List[str] = []
        for x in raw:
            if isinstance(x, int):
                i = x
            else:
                s = str(x).strip()
                if s.isdigit():
                    i = int(s, 10)
                else:
                    i = cls.DOW_IDX.get(s[:3].lower())
            if i is None or i < 0 or i > 6:
                continue
            out.append(cls.DOW_NAMES[i])
        # Keep original order but unique
        seen = set(); out2: List[str] = []
        for n in out:
            if n not in seen:
                seen.add(n); out2.append(n)
        return ','.join(out2)

    @classmethod
    def _oncalendar_for_interval(cls, i: dict) -> List[str]:
        """
        Convert one UI interval {minute:{value}, hour:{value}, day:{value}, month:{value}, year:{value}, dayOfWeek:[...]}
        into one or more systemd.calendar expressions (without the 'OnCalendar=' prefix).
        Supports DOW lists, minute steps (*/N -> *:0/N), hour steps (*/N -> 0,N,2N,...).
        """
        get = lambda k, default='*': str(i.get(k, {}).get('value', default))
        year  = get('year');   month = get('month'); day = get('day')
        hour  = get('hour', '*');    minute = get('minute', '*')
        dow   = cls._dow_expr(i)

        date_part = f"{year}-{month}-{day}"
        prefix = (dow + ' ') if dow else ''

        # minute: */N  => "*:0/N"
        if isinstance(minute, str) and minute.startswith('*/'):
            try:
                step = int(minute.split('/', 1)[1], 10)
            except Exception:
                step = 1
            return [f"{prefix}{date_part} *:0/{max(step,1)}"]

        # hour: */N  => expand 0,N,2N,... (minute fixed or 00)
        if isinstance(hour, str) and hour.startswith('*/'):
            try:
                step = int(hour.split('/', 1)[1], 10)
            except Exception:
                step = 1
            mm = '00' if minute in ('*', '', None) else cls._pad2(minute)
            return [f"{prefix}{date_part} {h:02d}:{mm}:00" for h in range(0, 24, max(step, 1))]

        # fixed/wildcards: allow '*' in any position
        hh = cls._pad2(hour) if hour != '*' else '*'
        mm = cls._pad2(minute) if minute != '*' else '*'
        return [f"{prefix}{date_part} {hh}:{mm}:00"]

    @classmethod
    def _oncalendar_lines(cls, schedule: dict) -> str:
        """Return newline-joined lines, each prefixed with 'OnCalendar='."""
        intervals = schedule.get('intervals') or [{}]
        lines: List[str] = []
        for i in intervals:
            lines.extend(cls._oncalendar_for_interval(i))
        # De-duplicate while preserving order
        seen = set(); ordered: List[str] = []
        for s in lines:
            if s not in seen:
                seen.add(s); ordered.append(s)
        if not ordered:
            ordered = ["*-*-* *:00:00"]
        return "\n".join(f"OnCalendar={s}" for s in ordered)


    # ---- API
    @dbus.service.method(IFACE, in_signature='', out_signature='a{sv}')
    def GetCapabilities(self):
        return {'version': '1', 'userUnits': True, 'rootUnits': True, 'rootsConfig': False}

    @dbus.service.method(IFACE, in_signature='', out_signature='as', sender_keyword='sender')
    def ListClientBackupFolders(self, sender=None):
        self._auth('com.45drives.scheduler.list', sender)
        _, uid = self._ids_from_sender(sender)

        out = []
        for root in self._backup_roots():
            if not root.exists():
                continue
            out.extend(self._list_user_owned_dirs(root, uid))
        return sorted(set(out))

    @dbus.service.method(IFACE, in_signature='s', out_signature='s', sender_keyword='sender')
    def ListTasks(self, scope, sender=None):
        self._auth('com.45drives.scheduler.list', sender)
        user = self._owner_for(template, name, sender) 

        def _read_kv(path):
            d = {}
            try:
                for line in pathlib.Path(path).read_text().splitlines():
                    if '=' in line:
                        k, v = line.split('=', 1)
                        d[k.strip()] = v.strip()
            except Exception:
                pass
            return d

        def _safe_json(path, default):
            try:
                return json.loads(pathlib.Path(path).read_text())
            except Exception:
                return default

        out = []

        if scope in ('user', 'all'):
            reg = self._registry_path(user)
            try:
                registry = json.loads(reg.read_text())
            except Exception:
                registry = []

            # index current registry for quick lookup
            seen = {(t.get('template'), t.get('name')) for t in registry if t.get('template') and t.get('name')}
           
            # 1) Return everything in registry
            for t in registry:
                name = t.get('name') or 'unnamed'
                template = t.get('template') or ''
                unit = self._unit_user(template, name, user)

                sdir = self._find_task_dir(user, name, unit)

                params   = _read_kv(sdir / f'{unit}.env')
                schedule = _safe_json(sdir / f'{unit}.json', t.get('schedule') or {"enabled": False, "intervals": []})
                notes    = (sdir / f'{unit}.txt').read_text() if (sdir / f'{unit}.txt').exists() else (t.get('notes') or '')

                out.append({
                    "name": name,
                    "template": template,
                    "scope": "user",
                    "unit": unit,
                    "params": params,
                    "schedule": schedule,
                    "notes": notes
                })

             # 2) Backfill: discover units not yet in registry
            for template, name, unit, sdir in self._discover_user_units(user):
                if (template, name) in seen:
                    continue
                params = {}
                try:
                    params = {k.strip(): v.strip()
                            for k,v in (line.split('=',1) for line in (sdir / f'{unit}.env').read_text().splitlines()
                                        if '=' in line)}
                except Exception:
                    pass
                try:
                    schedule = json.loads((sdir / f'{unit}.json').read_text())
                except Exception:
                    schedule = {"enabled": False, "intervals": []}
                notes = ''
                try:
                    notes = (sdir / f'{unit}.txt').read_text()
                except Exception:
                    pass

                out.append({
                    "name": name,
                    "template": template,
                    "scope": "user",
                    "unit": unit,
                    "params": params,
                    "schedule": schedule,
                    "notes": notes
                })

                # Optional: persist into registry (self-heal)
                registry.append({'name': name, 'template': template, 'schedule': schedule, 'notes': notes, 'scope': 'user'})
                seen.add((template, name))
                
            # Write back only if we added something
            try:
                reg.write_text(json.dumps(registry, indent=2))
            except Exception:
                pass
             
        # ---- SYSTEM scope (scan /etc/systemd/system)
        if scope in ('system', 'all'):
            etc = pathlib.Path('/etc/systemd/system')
            envs = list(etc.glob('houston_scheduler_*_*.env'))
            for envp in envs:
                base = envp.name[:-4]  # strip .env
                # derive template + name
                # houston_scheduler_<Template>_<TaskName>
                try:
                    _, _, rest = base.partition('houston_scheduler_')
                    template, _, name = rest.partition('_')
                except Exception:
                    continue

                params   = _read_kv(envp)
                schedule = _safe_json(etc / f'{base}.json', {"enabled": False, "intervals": []})
                notes    = (etc / f'{base}.txt').read_text() if (etc / f'{base}.txt').exists() else ''

                out.append({
                    "name": name,
                    "template": template,
                    "scope": "system",
                    "unit": base,
                    "params": params,
                    "schedule": schedule,
                    "notes": notes
                })

        return json.dumps(out)

    @dbus.service.method(IFACE, in_signature='sa{ss}ssss', out_signature='b', sender_keyword='sender')
    def CreateTask(self, template, env, script_path, schedule_json, notes, run_as, sender=None):
        schedule = json.loads(schedule_json) if schedule_json else {}
        use_user = (run_as == 'user') or (run_as == 'auto' and template in USER_TEMPLATES)
        action = 'com.45drives.scheduler.modify.user' if use_user else 'com.45drives.scheduler.modify.system'
        self._auth(action, sender)
        user = self._owner_for(template, name, sender) 

        if template == 'CloudSyncTask':
            if use_user:
                _, _, home = self._user_ids(user)
                rclone_conf = os.path.join(home, '.config', 'rclone', 'rclone.conf')
            else:
                rclone_conf = '/root/.config/rclone/rclone.conf'

            # add both for clarity; your cloudsync-script picks up either
            env['RCLONE_CONFIG'] = rclone_conf
            env['cloudSyncConfig_rclone_config_path'] = rclone_conf
            
        name = env.get('taskName') or 'unnamed'
        base_legacy = self._unit_base(template, name)

        if use_user:
            unit = self._unit_user(template, name, user)

            # NEW: task dir grouped by task name
            task_dir = self._task_dir(user, name)

            # write state
            env_text = '\n'.join([f'{k}={v}' for k, v in env.items() if str(v) not in ('', '0')])
            (task_dir / f'{unit}.env').write_text(env_text)
            (task_dir / f'{unit}.json').write_text(json.dumps(schedule, indent=2))
            (task_dir / f'{unit}.txt').write_text(notes or '')

            # write unit files *in the same dir* (basename must remain the unit name)
            svc_tpl = (TEMPLATES_DIR / 'Task.service').read_text()
            exec_start = f'/usr/bin/python3 {script_path}'
            svc_text = (svc_tpl
                        .replace('{task_name}', unit)
                        .replace('{env_path}', str(task_dir / f'{unit}.env'))
                        .replace('{ExecStart}', exec_start))
            (task_dir / f'{unit}.service').write_text(svc_text)

            tim_tpl = (TEMPLATES_DIR / 'Schedule.timer').read_text()
            oncal_lines = self._oncalendar_lines(schedule)
            tim_text = (tim_tpl
                        .replace('{description}', f'Timer for {unit}')
                        .replace('{unit_name}', unit)
                        .replace('{on_calendar_lines}', oncal_lines))
            (task_dir / f'{unit}.timer').write_text(tim_text)

            # link from this dir
            self._link_user_units(user, task_dir, unit)
            if schedule.get('enabled'):
                self._systemctl_user(user, f'systemctl --user start {unit}.timer')

            # registry update
            regp = self._registry_path(user)
            try: tasks = json.loads(regp.read_text())
            except Exception: tasks = []
            tasks = [t for t in tasks if not (t.get('name') == name and t.get('template') == template)]
            tasks.append({'name': name, 'template': template, 'schedule': schedule, 'notes': notes, 'scope': 'user'})
            regp.write_text(json.dumps(tasks, indent=2))
            return True

        # --- system/legacy branch (root scope) ---
        unit = base_legacy
        etc = pathlib.Path('/etc/systemd/system'); ensure(etc)
        env_path = etc / f'{unit}.env'
        env_text = '\n'.join([f'{k}={v}' for k, v in env.items() if str(v) not in ('', '0')])
        env_path.write_text(env_text)
        (etc / f'{unit}.json').write_text(json.dumps(schedule, indent=2))
        (etc / f'{unit}.txt').write_text(notes or '')

        timer_tpl = TEMPLATES_DIR / 'Schedule.timer'
        _run_quiet([
            '/usr/bin/env','python3', str(SCRIPTS_DIR / 'task-file-creation.py'),
            '-t','create-task-schedule',
            '-tN', template,
            '-sP', script_path,
            '-e', str(env_path),
            '-tt', str(timer_tpl),
            '-s',  str(etc / f'{unit}.json')
        ], timeout=12, check=True)
        return True

    @dbus.service.method(IFACE, in_signature='ss', out_signature='b', sender_keyword='sender')
    def RunNow(self, template, name, sender=None):
        user = self._owner_for(template, name, sender) 
        unit_user = self._unit_user(template, name, user)
        unit_sys  = self._unit_base(template, name)
        task_dir = self._find_task_dir(user, name, unit_user)
        is_user = (task_dir / f'{unit_user}.service').exists() or (task_dir / f'{unit_user}.timer').exists()

        self._auth('com.45drives.scheduler.modify.user' if is_user
                else 'com.45drives.scheduler.modify.system', sender)

        if is_user:
            self._link_user_units(user, task_dir, unit_user)
            self._systemctl_user(user, f'systemctl --user start {unit_user}.service')
            return True

        _run_quiet(['/usr/bin/env','python3', str(SCRIPTS_DIR / 'run-task-now.py'), unit_sys],
                timeout=10, check=True)
        return True

    @dbus.service.method(IFACE, in_signature='sss', out_signature='b', sender_keyword='sender')
    def EnableSchedule(self, template, name, enabled, sender=None):
        user = self._owner_for(template, name, sender) 
        unit_user = self._unit_user(template, name, user)
        unit_sys  = self._unit_base(template, name)
        task_dir = self._find_task_dir(user, name, unit_user)
        is_user = (task_dir / f'{unit_user}.service').exists() or (task_dir / f'{unit_user}.timer').exists()


        self._auth('com.45drives.scheduler.modify.user' if is_user
                else 'com.45drives.scheduler.modify.system', sender)

        if is_user:
            self._link_user_units(user, task_dir, unit_user)
            if enabled == 'true':
                self._systemctl_user(user, f'systemctl --user start {unit_user}.timer')
            else:
                self._systemctl_user(user, f'systemctl --user stop {unit_user}.timer')
            return True

        _run_quiet(['systemctl','daemon-reload'], timeout=6)
        cmd = (['systemctl','enable','--now',f'{unit_sys}.timer'] if enabled == 'true'
            else ['systemctl','disable','--now',f'{unit_sys}.timer'])
        _run_quiet(cmd, timeout=10, check=True)
        return True

    @dbus.service.method(IFACE, in_signature='ss', out_signature='b', sender_keyword='sender')
    def DeleteTask(self, template, name, sender=None):
        user = self._owner_for(template, name, sender) 
        unit_user = self._unit_user(template, name, user)
        unit_sys  = self._unit_base(template, name)
        task_dir = self._find_task_dir(user, name, unit_user)
        is_user = (task_dir / f'{unit_user}.service').exists() or (task_dir / f'{unit_user}.timer').exists()

        self._auth('com.45drives.scheduler.modify.user' if is_user
                else 'com.45drives.scheduler.modify.system', sender)

        if is_user:
            # 1) disable/stop timer (ok if not enabled)
            try: self._systemctl_user(user, f'systemctl --user disable --now --runtime {unit_user}.timer || true')
            except Exception: pass

            # 2) stop service if running (oneshot usually inactive, but safe)
            try: self._systemctl_user(user, f'systemctl --user stop {unit_user}.service || true')
            except Exception: pass

            # 3) unlink runtime links created by `link --runtime`
            try:
                self._systemctl_user(user, f'systemctl --user unlink "{task_dir}/{unit_user}.timer" || true')
                self._systemctl_user(user, f'systemctl --user unlink "{task_dir}/{unit_user}.service" || true')
                self._unlink_runtime_slot(user, f'{unit_user}.service')
                self._unlink_runtime_slot(user, f'{unit_user}.timer')

            except Exception:
                pass

            # 4) clear failed state (optional)
            try: self._systemctl_user(user, 'systemctl --user reset-failed || true')
            except Exception: pass

            # 5) reload, then remove files
            try: self._systemctl_user(user, 'systemctl --user daemon-reload || true')
            except Exception: pass

            for p in ((task_dir / f'{unit_user}.timer'),
                    (task_dir / f'{unit_user}.service'),
                    (task_dir / f'{unit_user}.env'),
                    (task_dir / f'{unit_user}.json'),
                    (task_dir / f'{unit_user}.txt')):
                try: p.unlink()
                except FileNotFoundError: pass

            try: task_dir.rmdir()
            except Exception: pass

            regp = self._registry_path(user)
            try: tasks = json.loads(regp.read_text())
            except Exception: tasks = []
            tasks = [t for t in tasks if not (t.get('template') == template and t.get('name') == name)]
            regp.write_text(json.dumps(tasks, indent=2))
            return True


        _run_quiet(['/usr/bin/env','python3', str(SCRIPTS_DIR / 'remove-task-files.py'), unit_sys],
                timeout=10, check=True)
        return True
    
    @dbus.service.method(IFACE, in_signature='ssa{ss}ssss', out_signature='b', sender_keyword='sender')
    def UpdateTask(self, template, old_name, env, script_path, schedule_json, notes, run_as, sender=None):
        """
        Update an existing task (user or system).
        - If env['taskName'] changes, this becomes a rename(old_name -> new_name).
        - run_as: 'user' | 'system' | 'auto' (same semantics as CreateTask).
        """
        schedule = json.loads(schedule_json) if schedule_json else {}
        caller_user = self._owner_for(template, name, sender) 

        # CloudSync rclone config parity with CreateTask
        if template == 'CloudSyncTask':
            if run_as == 'user' or (run_as == 'auto' and template in USER_TEMPLATES):
                _, _, home = self._user_ids(caller_user)
                rclone_conf = os.path.join(home, '.config', 'rclone', 'rclone.conf')
            else:
                rclone_conf = '/root/.config/rclone/rclone.conf'
            env['RCLONE_CONFIG'] = rclone_conf
            env['cloudSyncConfig_rclone_config_path'] = rclone_conf

        new_name = env.get('taskName') or old_name
        is_rename = (new_name != old_name)

        # Decide scope + owner
        # 1) Prefer explicit run_as; 2) If 'auto': prefer existing owner (user scope) if found; else template policy.
        use_user = False
        owner_user = caller_user
        if run_as == 'user':
            use_user = True
            owner_user = caller_user
        elif run_as == 'system':
            use_user = False
        elif run_as == 'auto':
            # First, does a user-scope task exist already for ANY user?
            owner_guess = self._find_user_owner_any(template, old_name)
            if owner_guess:
                use_user = True
                owner_user = owner_guess
            else:
                use_user = (template in USER_TEMPLATES)
        else:
            # Fallback: behave like 'auto'
            owner_guess = self._find_user_owner_any(template, old_name)
            if owner_guess:
                use_user = True
                owner_user = owner_guess
            else:
                use_user = (template in USER_TEMPLATES)

        if use_user:
            # --- USER SCOPE ---
            self._auth('com.45drives.scheduler.modify.user', sender)

            unit_old = self._unit_user(template, old_name, owner_user)
            unit_new = self._unit_user(template, new_name, owner_user)
            dir_old  = self._find_task_dir(owner_user, old_name, unit_old)
            dir_new  = self._task_dir(owner_user, new_name)

            # Write/refresh new files
            self._write_user_task_files(owner_user, template, new_name, env, schedule, notes, script_path)

            # If rename, clean old files/links/registry safely
            if is_rename:
                # stop/unlink old
                try: self._systemctl_user(owner_user, f'systemctl --user disable --now --runtime {unit_old}.timer || true')
                except Exception: pass
                try: self._systemctl_user(owner_user, f'systemctl --user stop {unit_old}.service || true')
                except Exception: pass
                try:
                    self._systemctl_user(owner_user, f'systemctl --user unlink "{dir_old}/{unit_old}.timer" || true')
                    self._systemctl_user(owner_user, f'systemctl --user unlink "{dir_old}/{unit_old}.service" || true')
                    self._unlink_runtime_slot(owner_user, f'{unit_old}.service')
                    self._unlink_runtime_slot(owner_user, f'{unit_old}.timer')
                except Exception:
                    pass
                try: self._systemctl_user(owner_user, 'systemctl --user daemon-reload || true')
                except Exception: pass

                for p in ((dir_old / f'{unit_old}.timer'),
                        (dir_old / f'{unit_old}.service'),
                        (dir_old / f'{unit_old}.env'),
                        (dir_old / f'{unit_old}.json'),
                        (dir_old / f'{unit_old}.txt')):
                    try: p.unlink()
                    except FileNotFoundError: pass
                try: dir_old.rmdir()
                except Exception: pass

            # Update registry to reflect latest (idempotent)
            regp = self._registry_path(owner_user)
            try: tasks = json.loads(regp.read_text())
            except Exception: tasks = []
            tasks = [t for t in tasks if not (t.get('template') == template and t.get('name') in (old_name, new_name))]
            tasks.append({'name': new_name, 'template': template, 'schedule': schedule, 'notes': notes, 'scope': 'user'})
            regp.write_text(json.dumps(tasks, indent=2))
            return True

        # --- SYSTEM / LEGACY SCOPE ---
        self._auth('com.45drives.scheduler.modify.system', sender)

        unit_old = self._unit_base(template, old_name)
        unit_new = self._unit_base(template, new_name)
        etc = pathlib.Path('/etc/systemd/system'); ensure(etc)

        # If renaming, create new first, then remove old
        def _write_system(unit):
            env_path = etc / f'{unit}.env'
            env_text = '\n'.join([f'{k}={v}' for k, v in env.items() if str(v) not in ('', '0')])
            env_path.write_text(env_text)
            (etc / f'{unit}.json').write_text(json.dumps(schedule, indent=2))
            (etc / f'{unit}.txt').write_text(notes or '')
            timer_tpl = TEMPLATES_DIR / 'Schedule.timer'
            _run_quiet([
                '/usr/bin/env','python3', str(SCRIPTS_DIR / 'task-file-creation.py'),
                '-t','create-task-schedule',
                '-tN', template,
                '-sP', script_path,
                '-e', str(env_path),
                '-tt', str(timer_tpl),
                '-s',  str(etc / f'{unit}.json')
            ], timeout=12, check=True)
            _run_quiet(['systemctl','daemon-reload'], timeout=6)
            if schedule.get('enabled'):
                _run_quiet(['systemctl','enable','--now',f'{unit}.timer'], timeout=10, check=True)
            else:
                _run_quiet(['systemctl','disable','--now',f'{unit}.timer'], timeout=10)

        _write_system(unit_new)

        if is_rename and unit_old != unit_new:
            # best-effort removal of old
            _run_quiet(['systemctl','disable','--now',f'{unit_old}.timer'], timeout=10)
            _run_quiet(['/usr/bin/env','python3', str(SCRIPTS_DIR / 'remove-task-files.py'), unit_old],
                    timeout=10)   # non-fatal if already gone

        return True

    
    @dbus.service.method(IFACE, in_signature='ss', out_signature='a{sv}', sender_keyword='sender')
    def GetStatus(self, template, name, sender=None):
        self._auth('com.45drives.scheduler.list', sender)
        user = self._owner_for(template, name, sender) 
        unit_user = self._unit_user(template, name, user)
        unit_sys  = self._unit_base(template, name)

        # Common property set the UI needs
        props = ('LoadState,ActiveState,SubState,Result,'
                'LastTriggerUSec,LastTrigger,NextElapseUSecRealtime,'
                'ActiveEnterTimestampUSec,ActiveEnterTimestamp,'
                'ExecMainStartTimestampUSec,ExecMainStartTimestamp,'
                'MergedUnit')

        task_dir = self._find_task_dir(user, name, unit_user)
        if (task_dir / f'{unit_user}.service').exists() or (task_dir / f'{unit_user}.timer').exists():
            # Link + reload (idempotent)
            try:
                self._link_user_units(user, task_dir, unit_user)
            except Exception:
                pass

            svc = self._systemctl_user_out(
                user,
                f'systemctl --user show {unit_user}.service --no-pager --property={props}'
            )
            tim = self._systemctl_user_out(
                user,
                f'systemctl --user show {unit_user}.timer --no-pager --property={props}'
            )
            return {'scope':'user','unit':unit_user,'service':svc,'timer':tim}

        # system scope
        def _show_sys(u):
            return _cmd_out(['systemctl','show',u,'--no-pager','--property',props])
        return {'scope':'system','unit':unit_sys,
                'service':_show_sys(f'{unit_sys}.service'),
                'timer':  _show_sys(f'{unit_sys}.timer')}

# ---- Clean shutdown: drop the D-Bus name immediately and quit GLib loop
def main():
    dbus.mainloop.glib.DBusGMainLoop(set_as_default=True)
    bus = dbus.SystemBus()
    loop = GLib.MainLoop()
    name_owner = dbus.service.BusName(BUS_NAME, bus)

    daemon = Daemon(bus, loop, name_owner)

    def _shutdown(signum, frame):
        logging.info("Shutdown signal received, releasing D-Bus name and quitting loop...")
        try:
            name_owner.release()  # free the name ASAP so the next instance can start
        except Exception:
            pass
        try:
            bus.close()
        except Exception:
            pass
        try:
            GLib.idle_add(loop.quit)
        except Exception:
            pass

    signal.signal(signal.SIGTERM, _shutdown)
    signal.signal(signal.SIGINT, _shutdown)

    loop.run()

if __name__ == '__main__':
    main()